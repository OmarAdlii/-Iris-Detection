{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as alb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b174670-8acd-49f5-9986-46387f7481cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data/images and data labels to save image and labels\n",
    "images_path=os.path.join('data','images')\n",
    "labels_path=os.path.join('data','labels')\n",
    "num_images=80\n",
    "try:\n",
    "    os.makedirs(os.path.join(images_path))\n",
    "    os.makedirs(os.path.join(labels_path))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36692594-326f-4867-8b8b-8b043594e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "for image_num in range(num_images):\n",
    "    print(f'Collecting image {image_num}')\n",
    "    ret,frame=cap.read()\n",
    "    image_name=os.path.join(images_path,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(image_name,frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    time.sleep(0.5)\n",
    "    if cv2.waitKey(1)& 0xFF ==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694152f-885f-4940-8960-5ee33131fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd01100-cd04-4cc3-8b02-33d72e64d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for folder in ['train','val','test']:\n",
    "        os.makedirs(os.path.join('data',folder,'images'))\n",
    "        os.makedirs(os.path.join('data',folder,'labels'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e2ad9-86eb-46cf-945d-a2091c2cb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for folder in ['train','val','test']:\n",
    "        os.makedirs(os.path.join('aug_data',folder,'images'))\n",
    "        os.makedirs(os.path.join('aug_data',folder,'labels'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9ff5a-118a-4cda-82dc-a37a9d2ac5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting a dataset of images and corresponding JSON label files into three sets: train, validation, and test. \n",
    "images_list=os.listdir(images_path)\n",
    "data_len=len(images_list)\n",
    "random.shuffle(images_list)\n",
    "ratio=(0.7,0.2,0.1)\n",
    "train_list=images_list[:int(ratio[0]*data_len)]\n",
    "val_list=images_list[int(ratio[0]*data_len):int(ratio[0]*data_len)+int(ratio[1]*data_len)]\n",
    "test_list=images_list[int(ratio[0]*data_len)+int(ratio[1]*data_len):]\n",
    "for file in train_list:\n",
    "    filename=file.split('.')[0]\n",
    "    old_image_dir=os.path.join(images_path,filename+'.jpg')\n",
    "    old_label_dir=os.path.join(labels_path,filename+'.json')\n",
    "    new_image_dir=os.path.join('data','train','images',filename+'.jpg')\n",
    "    new_label_dir=os.path.join('data','train','labels',filename+'.json')\n",
    "    try:\n",
    "        os.replace(old_image_dir,new_image_dir)\n",
    "        os.replace(old_label_dir,new_label_dir)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for file in val_list:\n",
    "    filename=file.split('.')[0]\n",
    "    old_image_dir=os.path.join(images_path,filename+'.jpg')\n",
    "    old_label_dir=os.path.join(labels_path,filename+'.json')\n",
    "    new_image_dir=os.path.join('data','val','images',filename+'.jpg')\n",
    "    new_label_dir=os.path.join('data','val','labels',filename+'.json')\n",
    "    try:\n",
    "        os.replace(old_image_dir,new_image_dir)\n",
    "        os.replace(old_label_dir,new_label_dir)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for file in test_list:\n",
    "    filename=file.split('.')[0]\n",
    "    old_image_dir=os.path.join(images_path,filename+'.jpg')\n",
    "    old_label_dir=os.path.join(labels_path,filename+'.json')\n",
    "    new_image_dir=os.path.join('data','test','images',filename+'.jpg')\n",
    "    new_label_dir=os.path.join('data','test','labels',filename+'.json')\n",
    "    try:\n",
    "        os.replace(old_image_dir,new_image_dir)\n",
    "        os.replace(old_label_dir,new_label_dir)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641108cb-9a39-4ac2-be46-8f31ad9bf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_list),len(val_list),len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be1236-bd81-4f18-97d5-37f34a93fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an augmentation pipeline using Albumentations\n",
    "augmentor=alb.Compose([alb.RandomCrop(width=450,height=450),\n",
    "                      alb.HorizontalFlip(p=0.5),\n",
    "                      alb.RandomBrightnessContrast(p=0.2),\n",
    "                      alb.RandomGamma(p=0.2),\n",
    "                      alb.RGBShift(0.2),\n",
    "                      alb.VerticalFlip(p=0.5)],\n",
    "                     keypoint_params=alb.KeypointParams(format='xy',label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2846e4-a9c3-45b8-b821-db866cc7e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over the three folders: 'train', 'val', and 'test' to augmentation\n",
    "for folder in ['train','val','test']:\n",
    "    for image in os.listdir(os.path.join('data',folder,'images')):\n",
    "        image_path=os.path.join('data',folder,'images',image)\n",
    "        img=cv2.imread(image_path)\n",
    "        label_path=os.path.join('data',folder,'labels',f'{image.split(\".\")[0]}.json')\n",
    "        classes=[0,0]\n",
    "        coords=[0,0,0.0000001,0.0000001]\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path,'r') as f:\n",
    "                label=json.load(f)\n",
    "            if label['shapes'][0]['label']=='left_eye':\n",
    "                classes[0]=1\n",
    "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "            if label['shapes'][0]['label']=='right_eye':\n",
    "                classes[1]=1\n",
    "                coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "            if len(label['shapes']) > 1:\n",
    "                if label['shapes'][1]['label']=='left_eye':\n",
    "                    classes[0]=1\n",
    "                    coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "                if label['shapes'][1]['label']=='right_eye':\n",
    "                    classes[1]=1\n",
    "                    coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "            \n",
    "            np.divide(coords, [640,480,640,480])\n",
    "            \n",
    "        try: \n",
    "            for x in range(40):\n",
    "                keypoints = [(coords[:2]), (coords[2:])]\n",
    "                augmented = augmentor(image=img, keypoints=keypoints, class_labels=['left_eye','right_eye'])\n",
    "                cv2.imwrite(os.path.join('aug_data', folder, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                annotation['class'] = [0,0]\n",
    "                annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['keypoints']) > 0: \n",
    "                        for idx, cl in enumerate(augmented['class_labels']):\n",
    "                            if cl == 'left_eye': \n",
    "                                annotation['class'][0] = 1 \n",
    "                                annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
    "                            if cl == 'right_eye': \n",
    "                                annotation['class'][1] = 1 \n",
    "                                annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
    "                                \n",
    "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', folder, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22059a-50fa-4eb4-8c08-648ee6b85925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read an image file given its file path \n",
    "def load_image(x):\n",
    "    byte_img=tf.io.read_file(x)\n",
    "    img=tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60730753-27f6-4bda-92d3-3b9e94fc0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and preprocess image data for the train, validation, and test sets\n",
    "train_images=tf.data.Dataset.list_files(os.path.join('aug_data','train','images','*'),shuffle=False)\n",
    "train_images=train_images.map(load_image)\n",
    "train_images=train_images.map(lambda x: tf.image.resize(x,(250,250))/255.0) #resize and normalize images\n",
    "val_images=tf.data.Dataset.list_files(os.path.join('aug_data','val','images','*'),shuffle=False)\n",
    "val_images=val_images.map(load_image)\n",
    "val_images=val_images.map(lambda x:tf.image.resize(x,(250,250))/255.0)\n",
    "test_images=tf.data.Dataset.list_files(os.path.join('aug_data','test','images','*'),shuffle=False)\n",
    "test_images=test_images.map(load_image)\n",
    "test_images=test_images.map(lambda x: tf.image.resize(x,(250,250))/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d62640-e931-4f56-8596-f151f29b13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "    return [label['keypoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d25cb7-0f75-4d84-8637-5af0cf987124",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files(os.path.join('aug_data','train','labels','*'), shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n",
    "val_labels = tf.data.Dataset.list_files(os.path.join('aug_data','val','labels','*'), shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n",
    "test_labels = tf.data.Dataset.list_files(os.path.join('aug_data','test','labels','*'), shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e83879-02a0-4ad7-b6e5-3536fe73eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images),len(train_labels),len(val_images),len(val_labels),len(test_images),len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d1fb0-29af-48e5-98f4-e63ac21d7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.data.Dataset.zip((train_images,train_labels))\n",
    "train=train.shuffle(train.cardinality())\n",
    "train=train.batch(8)\n",
    "train=train.prefetch(4)\n",
    "val=tf.data.Dataset.zip((val_images,val_labels))\n",
    "val=val.shuffle(val.cardinality())\n",
    "val=val.batch(8)\n",
    "val=val.prefetch(4)\n",
    "test=tf.data.Dataset.zip((test_images,test_labels))\n",
    "test=test.shuffle(test.cardinality())\n",
    "test=test.batch(8)\n",
    "test=test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fddc1-1fa6-406f-9b6b-cb9cacfa4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train),len(val),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d66bc-a72f-4cee-bd66-df8dc1ce0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples=train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fff32-ecc3-42a6-9e38-3a6db7a13291",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=data_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a6dcd-56de-4566-882c-3249c25b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=4,figsize=(20,20))\n",
    "for idx in range(4):\n",
    "    sample_image=res[0][idx]\n",
    "    sample_coords=res[1][0][idx]\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
    "    ax[idx].imshow(sample_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e75ac-e868-4134-b53b-f70f3bd144d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dropout,Input,Reshape\n",
    "from tensorflow.keras.applications import ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c95395-33a5-4bfb-9a64-7490ef24abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential([Input(shape=(250,250,3)),\n",
    "                  ResNet152V2(include_top=False,input_shape=(250,250,3)),\n",
    "                  Conv2D(512,3,padding='same',activation='relu'),\n",
    "                  Conv2D(512,3,padding='same',activation='relu'),\n",
    "                  Conv2D(256,3,2,padding='same',activation='relu'),\n",
    "                  Conv2D(256,2,2,activation='relu'),\n",
    "                  Dropout(0.05),\n",
    "                  Conv2D(4,2,2),\n",
    "                  Reshape((4,))])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48757c-2871-479b-a658-d7d779412de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimaizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss=tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942e759-153e-4e62-aa5e-63178b416e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimaizer,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08f153-4c23-44e6-89b4-5b9bf9cd9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31a504-ee15-4f01-857e-a36f307c5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(X)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8d771-4912-4ea5-9486-b83f3cde7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "histroy=model.fit(train,epochs=100,validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880df13-099c-4188-aa4e-0ec8d8ad1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "histroy.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84959fdc-511c-4669-985c-e7bc3b889ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histroy.history['loss'], color='teal', label='loss')\n",
    "plt.plot(histroy.history['val_loss'], color='orange', label='val loss')\n",
    "plt.suptitle('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a7fca-cd4e-498e-98c9-b409da8c65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cdae1-41cb-4052-8386-584b57d6ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35055358-e09f-4065-92e1-75fe1c28674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc22ab-0753-4ece-8b37-34791a96db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    sample_coords = yhat[idx]\n",
    "    \n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24410540-e0c3-4f03-8764-c0026db36dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5b66b-de37-4f4a-968d-cfad4c182e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('eyetrackerresnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1723f-7e2d-40d9-9b11-6af5af4a9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('eyetrackerresnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc86da-bba5-4822-a95e-3509a824bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c1d82-9db9-4bb7-939c-d0de680c443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    \n",
    "    frame = frame[50:500,50:500,:] \n",
    "    rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(rgb_img, (250,250))\n",
    "    \n",
    "    yhat = model.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[0,:4]\n",
    "    \n",
    "    cv2.circle(frame, tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(frame, tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7ffc8-686c-479f-9a5d-2dc7784b9984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
